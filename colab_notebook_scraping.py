# -*- coding: utf-8 -*-
"""colab_notebook_scraping.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1L4T4WcH5dxql9DAPV_bywgaJrHJY5jFe
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install selenium
# !apt-get update
# !apt install chromium-chromedriver
# !cp /usr/lib/chromium-browser/chromedriver /usr/bin

import sys
sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')
from selenium import webdriver
from tqdm.notebook import tqdm as tqdm
import pandas
import json
import pprint

chrome_options = webdriver.ChromeOptions()
chrome_options.add_argument('--headless')
chrome_options.add_argument('--no-sandbox')
chrome_options.add_argument('--disable-dev-shm-usage')

wd = webdriver.Chrome('chromedriver',chrome_options=chrome_options)

def loop_offer_pages(x):

  id = x.get_attribute("data-guid") #guid dell'annuncio
  try:
    page = x.find_element_by_css_selector(".cldt-summary-titles > a").get_attribute("href") #pagina dell'annauncio
    vehicle = x.find_element_by_css_selector(".cldt-summary-makemodel.sc-font-bold.sc-ellipsis").text
    price = x.find_elements_by_css_selector("""[data-item-name="price"]""")[0].text # 23 restituisce se c'è una rata, iva dedicibile etc
    vehicle_data = x.find_elements_by_css_selector(".cldt-summary-vehicle-data")[0].text.split("\n")
  except:
    page = ""
    vehicle = ""
    price = ""
    vehicle_data = ""
  try:
    vehicle_usr_desc = x.find_elements_by_css_selector(".cldt-summary-version")[0].text
  except:
     vehicle_usr_desc = ""
  seller_list = x.find_elements_by_css_selector("""[data-item-name="seller"]""")[0].text.split("\n")
  if seller_list[1].find('(') != -1:
    del seller_list[1]
  seller = seller_list[0]
  seller_country = seller_list[1]
  seller_address = seller_list[2]
  return {
      'id_annuncio': id,
      'link_annuncio': page,
      'vehicle': vehicle,
      'vehicle_user_desc' : vehicle_usr_desc,
      'asking_price' : price,
      'seller' : seller,
      'country' : seller_country,
      'address' : seller_address,
      }

from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import numpy as np
import requests
import urllib.request
import os
import time

#create blank list to enclose all offers page results
output_scraping = []
tipo_carrozzeria = [1,2,3,4,5,6,7,12]
fuel =  "B" #["B","D","E","L","C","2"]
condizione_auto = "N" #N nuovo, S KM0, U usato

for j in tqdm(tipo_carrozzeria):
  for i in tqdm(range(1,21)): #range to all pages is 21

    url = "https://www.autoscout24.it/lst/?sort=age&" + "offer=" + condizione_auto + "&desc=1&fuel=" + str(fuel) + "&ustate=N%2CU&size=20&page=" + str(i) + \
    "&lon=9.18812&lat=45.46362&zip=Milano&zipr=200&cy=I&body=" + str(j) + "&atype=C&fc=14&qry=&"

    print("Pagina: " + str(i) + ", condition: " + condizione_auto + ", fuel: " + str(fuel) + ", tipo carrozzeria: " + str(j) + " url: " + url)
    #time.sleep(abs(np.random.normal(1,.5)))
    wd.set_window_size(1920,1080)
    wd.get(url)

    try:
      WebDriverWait(wd, 7).until(
          EC.element_to_be_clickable((By.CSS_SELECTOR, "a.active")) #loads bottom bar, which is the last to be loaded in chromium
      )
    except:
      continue
    
    lista_annunci = wd.find_elements_by_css_selector(".cl-list-element.cl-list-element-gap")

    for x in lista_annunci:
      output_scraping.append(loop_offer_pages(x))
  
    if len(lista_annunci) < 20: #exit if there are less than 20 offers on 1 page
      break

print(output_scraping)

import json
export_output_scraping = open('pagina_di_ricerca_fuel_' + fuel + '_condition_' + condizione_auto + '.json', mode='w+')
export_output_scraping.write(json.dumps(output_scraping, indent=3))
export_output_scraping.close()

details_raw = []
details_value = wd.find_elements_by_css_selector("""[data-item-name="car-details"] >* dd""")
details_field = wd.find_elements_by_css_selector("""[data-item-name="car-details"] >* dt""")
for i in range(0,len(details_field)):
  details_raw_field = details_field[i].text
  details_raw_value = details_value[i].text
  if details_raw_value == "":
    details_raw_value = "Sì"
  details_raw.append(details_raw_field)
  details_raw.append(details_raw_value)

it = iter(details_raw) 
details = dict(zip(it, it)) 
print(details)

def loop_single_offer_pages(k):
  url = k['link_annuncio']
  wd.set_window_size(1920,1080)
  wd.get(url)

  details_raw = []
  details_value = wd.find_elements_by_css_selector("""[data-item-name="car-details"] >* dd""")
  details_field = wd.find_elements_by_css_selector("""[data-item-name="car-details"] >* dt""")

  for m in range(0,len(details_field)):
    details_raw_field = details_field[m].text
    details_raw_value = details_value[m].text
    if details_raw_value == "":
      details_raw_value = "Sì"
    details_raw.append(details_raw_field)
    details_raw.append(details_raw_value)
  it = iter(details_raw) 
  details = dict(zip(it, it)) 
  details['id_annuncio'] = k['id_annuncio']
  
  return details

output_single_offers_scraping = []

for i in tqdm(output_scraping):
  output_single_offers_scraping.append(loop_single_offer_pages(i))

print (len(output_single_offers_scraping))

export_output_single_offers_scraping = open('singole_pagine_fuel_' + fuel + '_condition_' + condizione_auto + '.json', mode='w+')
export_output_single_offers_scraping.write(json.dumps(output_single_offers_scraping, indent=3))
export_output_single_offers_scraping.close()